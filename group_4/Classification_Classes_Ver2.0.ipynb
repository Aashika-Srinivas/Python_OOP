{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Sepal Length  150 non-null    float64\n",
      " 1   Sepal Width   150 non-null    float64\n",
      " 2   Petal Length  150 non-null    float64\n",
      " 3   Petal Width   150 non-null    float64\n",
      " 4   Class         150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Random Forest Score : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictive Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predictive Accuracy\n",
       "Random Forest                  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The prediction results - Y Test vs Y Prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted by Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Actual Predicted by Random Forest\n",
       "0   Iris-versicolor            Iris-versicolor\n",
       "1       Iris-setosa                Iris-setosa\n",
       "2    Iris-virginica             Iris-virginica\n",
       "3   Iris-versicolor            Iris-versicolor\n",
       "4   Iris-versicolor            Iris-versicolor\n",
       "5       Iris-setosa                Iris-setosa\n",
       "6   Iris-versicolor            Iris-versicolor\n",
       "7    Iris-virginica             Iris-virginica\n",
       "8   Iris-versicolor            Iris-versicolor\n",
       "9   Iris-versicolor            Iris-versicolor\n",
       "10   Iris-virginica             Iris-virginica\n",
       "11      Iris-setosa                Iris-setosa\n",
       "12      Iris-setosa                Iris-setosa\n",
       "13      Iris-setosa                Iris-setosa\n",
       "14      Iris-setosa                Iris-setosa\n",
       "15  Iris-versicolor            Iris-versicolor\n",
       "16   Iris-virginica             Iris-virginica\n",
       "17  Iris-versicolor            Iris-versicolor\n",
       "18  Iris-versicolor            Iris-versicolor\n",
       "19   Iris-virginica             Iris-virginica\n",
       "20      Iris-setosa                Iris-setosa\n",
       "21   Iris-virginica             Iris-virginica\n",
       "22      Iris-setosa                Iris-setosa\n",
       "23   Iris-virginica             Iris-virginica\n",
       "24   Iris-virginica             Iris-virginica\n",
       "25   Iris-virginica             Iris-virginica\n",
       "26   Iris-virginica             Iris-virginica\n",
       "27   Iris-virginica             Iris-virginica\n",
       "28      Iris-setosa                Iris-setosa\n",
       "29      Iris-setosa                Iris-setosa\n",
       "30      Iris-setosa                Iris-setosa\n",
       "31      Iris-setosa                Iris-setosa\n",
       "32  Iris-versicolor            Iris-versicolor\n",
       "33      Iris-setosa                Iris-setosa\n",
       "34      Iris-setosa                Iris-setosa\n",
       "35   Iris-virginica             Iris-virginica\n",
       "36  Iris-versicolor            Iris-versicolor\n",
       "37      Iris-setosa                Iris-setosa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import csv\n",
    "\n",
    "\n",
    "# linear models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Non-linear models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# ensemble models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#random Number generation\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from scipy.stats import uniform \n",
    "\n",
    "#for splitting data into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for hyperparameter optimization\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "class Initialise: ##Class to initialise the train and test data sets\n",
    "    # Initialise\n",
    "    def __init__ (self, classifier_name,X_train, X_test, y_train, y_test):\n",
    "        self.classifier_name = classifier_name\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "    \n",
    "class LR_Class(Initialise): ##Inherting init method \n",
    "    #Initialise\n",
    "    def __init__ (self, classifier_name,X_train, X_test, y_train, y_test):\n",
    "        #Using class name again as __init__ method in child class overrides parent class\n",
    "        Initialise.__init__(self, classifier_name,X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    def lr_classifier(self): #Get other parameters from user\n",
    "        #we will start with the simple Logistic regression first. \n",
    "        lr = LogisticRegression(max_iter=1000)\n",
    "        #fitting the data on the model \n",
    "        lr.fit(self.X_train, self.y_train)\n",
    "        #predicted output\n",
    "        LR_predictions = lr.predict(self.X_test)\n",
    "        #score\n",
    "        lr_score=lr.score(self.X_test,self.y_test)\n",
    "        return lr_score, LR_predictions\n",
    "        \n",
    "class KNN_Class(Initialise): ##Inherting init method \n",
    "    #Initialise\n",
    "    def __init__ (self, classifier_name,X_train, X_test, y_train, y_test):\n",
    "         #Using class name again as __init__ method in child class overrides parent class\n",
    "        Initialise.__init__(self, classifier_name,X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    def knn_classifier(self):\n",
    "        knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "        knn.fit(self.X_train,self.y_train)\n",
    "        knn_score = knn.score(self.X_test,self.y_test)\n",
    "        knn_prediction = knn.predict(self.X_test)\n",
    "        return knn_score, knn_prediction\n",
    "    \n",
    "class SVM_Class(Initialise): ##Inherting init method \n",
    "    #Initialise\n",
    "    def __init__ (self, classifier_name,X_train, X_test, y_train, y_test):\n",
    "         #Using class name again as __init__ method in child class overrides parent class\n",
    "        Initialise.__init__(self, classifier_name,X_train, X_test, y_train, y_test)\n",
    "        \n",
    "    def svm_classifier(self): #Get other parameters from user\n",
    "        svm = SVC(random_state = 1)\n",
    "        svm.fit(self.X_train,self.y_train)\n",
    "        svm_score = svm.score(self.X_test,self.y_test)\n",
    "        svm_prediction = svm.predict(self.X_test)\n",
    "        return svm_score, svm_prediction\n",
    "      \n",
    "        \n",
    "class NB_Class(Initialise): ##Inherting init method \n",
    "    #Initialise\n",
    "    def __init__ (self, classifier_name,X_train, X_test, y_train, y_test):\n",
    "         #Using class name again as __init__ method in child class overrides parent class\n",
    "        Initialise.__init__(self, classifier_name,X_train, X_test, y_train, y_test)\n",
    "        \n",
    "    def nb_classifier(self):\n",
    "        nb = GaussianNB()\n",
    "        nb.fit(self.X_train,self.y_train)\n",
    "        nb_score = nb.score(self.X_test,self.y_test)\n",
    "        nb_prediction = nb.predict(self.X_test)\n",
    "        return nb_score, nb_prediction\n",
    "\n",
    "class DT_Class(Initialise): ##Inherting init method \n",
    "    #Initialise\n",
    "    def __init__ (self, classifier_name,X_train, X_test, y_train, y_test):\n",
    "         #Using class name again as __init__ method in child class overrides parent class\n",
    "        Initialise.__init__(self, classifier_name,X_train, X_test, y_train, y_test)\n",
    "            \n",
    "    def dt_classifier(self):\n",
    "        dt = DecisionTreeClassifier()\n",
    "        dt.fit(self.X_train,self.y_train)\n",
    "        dt_score = dt.score(self.X_test,self.y_test)\n",
    "        dt_prediction = dt.predict(self.X_test)\n",
    "        return dt_score, dt_prediction\n",
    "\n",
    "class RF_Class(Initialise): ##Inherting init method \n",
    "    #Initialise\n",
    "    def __init__ (self, classifier_name,X_train, X_test, y_train, y_test):\n",
    "        Initialise.__init__(self, classifier_name,X_train, X_test, y_train, y_test)\n",
    "         #Using class name again as __init__ method in child class overrides parent class\n",
    "        \n",
    "    def rf_classifier(self): #Get other parameters from user\n",
    "        rf = RandomForestClassifier(n_estimators = 22,random_state = 40)\n",
    "        rf.fit(self.X_train,self.y_train)\n",
    "        rf_score = rf.score(self.X_test,self.y_test)\n",
    "        rf_prediction = rf.predict(self.X_test)\n",
    "        return rf_score, rf_prediction\n",
    "    \n",
    "class Result: ##Class method to get final results and prediction for each classification algorithm\n",
    "    @classmethod\n",
    "    def get_results(self, classifier_name, score, y_test, y_predict):\n",
    "        print()\n",
    "        display (classifier_name + \" Score : \")\n",
    "        col={'Predictive Accuracy':score}\n",
    "        models=[classifier_name]\n",
    "        display(pd.DataFrame(data=col,index=models))\n",
    "        print()\n",
    "        print()\n",
    "        print(\"The prediction results - Y Test vs Y Prediction\")\n",
    "        display(pd.DataFrame({'Actual': y_test, 'Predicted by '+classifier_name: y_predict}))\n",
    "        \n",
    "        \n",
    "                      \n",
    "\n",
    "# load the dataset, returns X and y elements\n",
    "def load_dataset():\n",
    "    #url = \"C:/Users/Admin/Desktop/Iris-Data.csv\"\n",
    "    \n",
    "    url = 'C:/Users/Admin/Desktop/Iris-Data.csv'\n",
    "    #df = urllib2.urlopen(url)\n",
    "\n",
    "    df = pd.read_csv(url) \n",
    "    df.info()\n",
    "    X = df.drop(['Class'], axis =1)\n",
    "    y = df['Class'].values\n",
    "    return X, y\n",
    "\n",
    "#training test split is specified by train_size parameter. 0.8 means 80% data is training. \n",
    "#a good practice is to split into 75:25 ratio, but we can always change that.\n",
    "#source which helped me alot: https://www.kaggle.com/umutozdemir/comparison-of-different-regression-models\n",
    "\n",
    "X, y = load_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.75, shuffle = True, random_state = 42)\n",
    "\n",
    "score_list = [] #to keep scores of algorithms\n",
    "\n",
    "classifier_name =\"Random Forest\"\n",
    "\n",
    "if (classifier_name == \"Logistic Regression\"):\n",
    "    LRobj = LR_Class(classifier_name,X_train, X_test, y_train, y_test)\n",
    "    score, y_predict = LRobj.lr_classifier()\n",
    "    Result.get_results(classifier_name, score, y_test, y_predict)\n",
    "    \n",
    "elif (classifier_name == \"K-Nearest Neighbours\"):\n",
    "    KNNobj = KNN_Class(classifier_name,X_train, X_test, y_train, y_test)\n",
    "    score, y_predict = KNNobj.knn_classifier()\n",
    "    Result.get_results(classifier_name, score, y_test, y_predict)\n",
    "\n",
    "elif (classifier_name == \"State Vector Machine\"):\n",
    "    SVMobj = SVM_Class(classifier_name,X_train, X_test, y_train, y_test)\n",
    "    score, y_predict = SVMobj.svm_classifier()\n",
    "    Result.get_results(classifier_name, score, y_test, y_predict)\n",
    "    \n",
    "elif (classifier_name == \"Naive Bayes\"):\n",
    "    NBobj = NB_Class(classifier_name,X_train, X_test, y_train, y_test)\n",
    "    score, y_predict = NBobj.nb_classifier()\n",
    "    Result.get_results(classifier_name, score, y_test, y_predict)\n",
    "    \n",
    "elif (classifier_name == \"Decision Tree\"):\n",
    "    DTobj = DT_Class(classifier_name,X_train, X_test, y_train, y_test)\n",
    "    score, y_predict = DTobj.dt_classifier()\n",
    "    Result.get_results(classifier_name, score, y_test, y_predict)\n",
    "    \n",
    "elif (classifier_name == \"Random Forest\"):\n",
    "    RFobj = RF_Class(classifier_name,X_train, X_test, y_train, y_test)\n",
    "    score, y_predict = RFobj.rf_classifier()\n",
    "    Result.get_results(classifier_name, score, y_test, y_predict)\n",
    "    \n",
    "else:\n",
    "    print()\n",
    "    print (\"Check the Classification model selected\")\n",
    "            \n",
    "\n",
    "\n",
    "#pr_dict = {'Logistic Regression' : lr_prediction,'KNN' : knn_prediction,'SVM' : svm_prediction,\n",
    "           #'Naive Bayes' : nb_prediction,'Decision Tree' : dt_prediction, 'Random Forest' : rf_prediction}\n",
    "\n",
    "#all_predictions = pd.DataFrame(pr_dict)\n",
    "\n",
    "#all_predictions\n",
    "\n",
    "#Score=[lr_score,knn_score,svm_score,nb_score,dt_score,rf_score]\n",
    "\n",
    "#col={'Predictive Accuracy':Score}\n",
    "#models=['Logistic Regression','KNN Classifier','Support Vector Machines','Naive Bayes','Decision Trees','Random Forest']\n",
    "#df=pd.DataFrame(data=col,index=models)\n",
    "#print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
